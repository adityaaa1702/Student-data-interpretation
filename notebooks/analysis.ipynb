{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load preprocessed data from CSV\n",
    "preprocessed_data = pd.read_csv('data/preprocessed_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze performance\n",
    "def analyze_performance(data, test_id):\n",
    "\n",
    "    # Calculate total correct answers\n",
    "    total_correct_answers = data['is_correct'].sum()\n",
    "\n",
    "    # Calculate total number of questions attempted\n",
    "    total_questions_attempted = data[data['status'] == 'answered'].shape[0]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = total_correct_answers / total_questions_attempted if total_questions_attempted > 0 else 0\n",
    "\n",
    "    # Visualization: Create a bar chart\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    plt.bar(['Total Correct Answers', 'Total Questions Attempted', 'Accuracy'],\n",
    "            [total_correct_answers, total_questions_attempted, accuracy])\n",
    "    plt.title(f'Performance Analysis for Test ID: {test_id}')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Values')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Return performance metrics\n",
    "    return {\n",
    "        'test_id': test_id,\n",
    "        'total_correct_answers': total_correct_answers,\n",
    "        'total_questions_attempted': total_questions_attempted,\n",
    "        'accuracy': accuracy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_tests_performance():\n",
    "    \n",
    "\n",
    "    # Perform analysis for each test ID\n",
    "    test_ids = preprocessed_data['test_id'].unique()\n",
    "    for test_id in test_ids:\n",
    "        test_data = preprocessed_data[preprocessed_data['test_id'] == test_id]\n",
    "        performance_metrics = analyze_performance(test_data, test_id)\n",
    "        print(f\"Test ID: {test_id}\")\n",
    "        for metric, value in performance_metrics.items():\n",
    "            print(f\"{metric}: {value}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Call the main function\n",
    "analyze_all_tests_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot user performance\n",
    "def plot_user_performance(user_data):\n",
    "    # Get user ID\n",
    "    user_id = user_data['user_id'].iloc[0]\n",
    "    \n",
    "    # Group data by test ID and calculate total questions and correct answers\n",
    "    grouped_data = user_data.groupby('test_id').agg(total_questions=('question_id', 'count'),\n",
    "                                                    total_correct_answers=('is_correct', 'sum'))\n",
    "    \n",
    "    # Plot user performance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(grouped_data.index, grouped_data['total_questions'], color='lightblue', label='Total Questions')\n",
    "    plt.bar(grouped_data.index, grouped_data['total_correct_answers'], color='green', label='Correct Answers')\n",
    "    plt.xlabel('Test ID')\n",
    "    plt.ylabel('Number of Questions')\n",
    "    plt.title(f'User {user_id} Performance Across Tests')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print user performance\n",
    "def print_user_performance(data):\n",
    "    # Group data by user ID\n",
    "    grouped_data = data.groupby('user_id')\n",
    "    \n",
    "    # Iterate over each user's data\n",
    "    for user_id, user_data in grouped_data:\n",
    "        print(f\"User ID: {user_id}\")\n",
    "        plot_user_performance(user_data)       \n",
    "        \n",
    "        \n",
    " # Print user performance\n",
    "print_user_performance(preprocessed_data)       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to plot quality of time spent for a specific test\n",
    "def plot_time_spent_quality(test_data):\n",
    "    # Get test ID\n",
    "    test_id = test_data['test_id'].iloc[0]\n",
    "\n",
    "    # Calculate total time taken for the test\n",
    "    total_time_taken = test_data['time_taken'].sum()\n",
    "\n",
    "    # Calculate time taken for answered questions\n",
    "    answered_time_taken = test_data[test_data['status'] == 'answered']['time_taken'].sum()\n",
    "\n",
    "    # Calculate time for unanswered questions\n",
    "    unanswered_time_taken = total_time_taken - answered_time_taken\n",
    "\n",
    "    # Pie chart data\n",
    "    labels = ['Quality Time (Answered)', 'Other Time (Unanswered)']\n",
    "    sizes = [answered_time_taken, unanswered_time_taken]\n",
    "    colors = sns.color_palette('pastel')  # Using Seaborn color palette\n",
    "    explode = (0.1, 0)  # explode the 1st slice (Quality Time)\n",
    "\n",
    "    # Plot pie chart\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "            shadow=True, startangle=140)\n",
    "    plt.title(f'Time Spent Quality for Test ID: {test_id}')\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()\n",
    "\n",
    "# Function to print quality of time spent for all tests\n",
    "def print_time_spent_quality(data):\n",
    "    # Group data by test ID\n",
    "    grouped_data = data.groupby('test_id')\n",
    "\n",
    "    # Iterate over each test's data\n",
    "    for test_id, test_data in grouped_data:\n",
    "        plot_time_spent_quality(test_data)\n",
    "\n",
    "# Example usage\n",
    "# Load preprocessed data from CSV\n",
    "preprocessed_data = pd.read_csv('data/preprocessed_data.csv')\n",
    "\n",
    "# Print quality of time spent for each test\n",
    "print_time_spent_quality(preprocessed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
